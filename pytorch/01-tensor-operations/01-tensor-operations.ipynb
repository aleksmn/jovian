{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Interesting PyTorch Functions\n","\n","The torch package contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors. Additionally, it provides many utilities for efficient serializing of Tensors and arbitrary types, and other useful utilities.\n","\n","- torch.arange\n","- torch.chunk\n","- torch.narrow\n","- torch.take\n","- torch.where\n","\n","Before we begin, let's install and import PyTorch"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Uncomment and run the appropriate command for your operating system, if required\n","\n","# Linux / Binder\n","# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","# Windows\n","# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","# MacOS\n","# !pip install numpy torch torchvision torchaudio"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Import torch and other required modules\n","import torch"]},{"cell_type":"markdown","metadata":{},"source":["## Function 1 - torch.arange\n","\n","Returns a 1-D tensor of size `(end - start) / step` with values from the interval `[start, end)` taken with common difference `step` beginning from start.\n","\n","Note that non-integer step is subject to floating point rounding errors when comparing against end; to avoid inconsistency, we advise adding a small epsilon to end in such cases."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 2, 3, 4, 5, 6, 7])"]},"metadata":{},"execution_count":6}],"source":["# Example 1 (working)\n","torch.arange(8)"]},{"cell_type":"markdown","metadata":{},"source":["Tensor from 0 to 8."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([5.0000, 5.2000, 5.4000, 5.6000, 5.8000])"]},"metadata":{},"execution_count":10}],"source":["# Example 2 (working)\n","torch.arange(5, 6, 0.2)"]},{"cell_type":"markdown","metadata":{},"source":["Tensor from 5 to 6 with step 0.2."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"arange() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Number end, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Number end, Number step, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-156204f692e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: arange() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Number end, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (Number start, Number end, Number step, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"]}],"source":["# Example 3 - breaking (to illustrate when it breaks)\n","torch.arange([2, 3], 2)"]},{"cell_type":"markdown","metadata":{},"source":["First argument can not be a list. "]},{"cell_type":"markdown","metadata":{},"source":["## Function 2 - torch.chunk\n","\n","Splits a tensor into a specific number of chunks. Each chunk is a view of the input tensor."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([5.0000, 5.2000, 5.4000, 5.6000, 5.8000, 6.0000, 6.2000, 6.4000, 6.6000,\n","         6.8000, 7.0000, 7.2000, 7.4000]),\n"," tensor([7.6000, 7.8000, 8.0000, 8.2000, 8.4000, 8.6000, 8.8000, 9.0000, 9.2000,\n","         9.4000, 9.6000, 9.8000]))"]},"metadata":{},"execution_count":14}],"source":["# Example 1 - working\n","mytorch = torch.arange(5, 10, 0.2)\n","mytorch.chunk(2)"]},{"cell_type":"markdown","metadata":{},"source":["Split tensor by 2."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1],\n","         [4]]),\n"," tensor([[3],\n","         [5]]))"]},"metadata":{},"execution_count":31}],"source":["# Example 2 - working\n","mytorch_2 = torch.tensor([[1, 3],[4, 5]])\n","mytorch_2.chunk(2, 1)"]},{"cell_type":"markdown","metadata":{},"source":["Split tensot on second dimension."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"output_type":"error","ename":"IndexError","evalue":"Dimension out of range (expected to be in range of [-2, 1], but got 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-7f600b60bd72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmytorch_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmytorch_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"]}],"source":["# Example 3 - breaking (to illustrate when it breaks)\n","mytorch_3 = torch.tensor([[1, 3],[4, 5]])\n","mytorch_3.chunk(2, 2)"]},{"cell_type":"markdown","metadata":{},"source":["Given dimension is out of range"]},{"cell_type":"markdown","metadata":{},"source":["## Function 3 - torch.narrow\n","\n","`torch.narrow(input, dim, start, length) â†’ Tensor`\n","\n","Returns a new tensor that is a narrowed version of input tensor. The dimension `dim` is input from `start` to `start + length`. The returned tensor and `input` tensor share the same underlying storage."]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1],\n","        [4],\n","        [7]])"]},"metadata":{},"execution_count":43}],"source":["# Example 1 - working\n","x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","torch.narrow(x, 1, 0, 1)"]},{"cell_type":"markdown","metadata":{},"source":["Output is first item from every element."]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[7, 8, 9]])"]},"metadata":{},"execution_count":47}],"source":["# Example 2 - working\n","torch.narrow(x, 0, -1, 1)"]},{"cell_type":"markdown","metadata":{},"source":["Output is last element."]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"output_type":"error","ename":"IndexError","evalue":"Dimension out of range (expected to be in range of [-2, 1], but got 3)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-14c5363b6b73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 3)"]}],"source":["# Example 3 - breaking (to illustrate when it breaks)\n","torch.narrow(x, 3, 0, 1)"]},{"cell_type":"markdown","metadata":{},"source":["Given dimension (3) is out of range."]},{"cell_type":"markdown","metadata":{},"source":["## Function 4 - torch.take\n","\n","Returns a new tensor with the elements of input at the given indices. The input tensor is treated as if it were viewed as a 1-D tensor. The result takes the same shape as the indices."]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2, 5, 6])"]},"metadata":{},"execution_count":53}],"source":["# Example 1 - working\n","\n","x = torch.tensor([[1, 2, 3],\n","                  [4, 5, 6]])\n","torch.take(x, torch.tensor([1, 4, 5]))"]},{"cell_type":"markdown","metadata":{},"source":["Output is 1 ,4, 5 elements from source tensor."]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2, 2, 2])"]},"metadata":{},"execution_count":56}],"source":["# Example 2 - working\n","torch.take(x, torch.tensor([1, 1, 1]))"]},{"cell_type":"markdown","metadata":{},"source":["Element with index 1 repeated 3 times."]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"invalid argument 2: out of range: 8 out of 6 at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:212","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-64f31760f982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: out of range: 8 out of 6 at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:212"]}],"source":["# Example 3 - breaking (to illustrate when it breaks)\n","torch.take(x, torch.tensor([1, 4, 8]))"]},{"cell_type":"markdown","metadata":{},"source":["Element ois out of range."]},{"cell_type":"markdown","metadata":{},"source":["## Function 5 - torch.where\n","\n","Return a tensor of elements selected from either x or y, depending on condition."]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.1413, -2.3044],\n        [-0.4091, -1.0444],\n        [ 0.7305,  1.1479]])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1.0000, 1.0000],\n","        [1.0000, 1.0000],\n","        [0.7305, 1.1479]])"]},"metadata":{},"execution_count":75}],"source":["# Example 1 - working\n","\n","x = torch.randn(3, 2)\n","y = torch.ones(3, 2)\n","print(x)\n","# print(y)\n","torch.where(x > 0.5, x, y)"]},{"cell_type":"markdown","metadata":{},"source":["If x > 0.5 return x, else return y."]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.,  0., 12.,  8.,  0.], dtype=torch.float64)"]},"metadata":{},"execution_count":95}],"source":["# Example 2 - working\n","x = torch.tensor([-1.5, 0, 12, 8, -5], dtype=torch.float64)\n","torch.where(x > 0, x, .0)"]},{"cell_type":"markdown","metadata":{},"source":["Return element > 0, else return 0."]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"expected scalar type double but found long int","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-96-3b0de430b3fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: expected scalar type double but found long int"]}],"source":["# Example 3 - breaking (to illustrate when it breaks)\n","torch.where(x > 0, x, 0)"]},{"cell_type":"markdown","metadata":{},"source":["Dtype in condition do not match."]},{"cell_type":"markdown","metadata":{},"source":["## Conclusion\n","PyTorch has a lot of powerfull functions for data manipulation. The official documentation of PyTorch is very usefull and simple to understand.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Reference Links\n","Provide links to your references and other interesting articles about tensors\n","* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html\n","* PyTorch Get Started: https://pytorch.org/get-started/locally/"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[jovian] Update Available: 0.2.38 --> 0.2.41\n","[jovian] Run `!pip install jovian --upgrade` to upgrade\n"]},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[jovian] Attempting to save notebook..\n","[jovian] Uploading notebook..\n","[jovian] Capturing environment..\n","[jovian] Error: Failed to read Anaconda environment using command: \"conda env export -n base --no-builds\"\n","[jovian] Committed successfully! https://jovian.ai/aleksmn/01-tensor-operations\n"]},{"output_type":"execute_result","data":{"text/plain":["'https://jovian.ai/aleksmn/01-tensor-operations'"]},"metadata":{},"execution_count":98}],"source":["import jovian\n","jovian.commit(filename='01-tensor-operations.ipynb')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit"},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"nbformat":4,"nbformat_minor":4}