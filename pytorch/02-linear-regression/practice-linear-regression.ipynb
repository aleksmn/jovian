{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Practice Gradient Descent and Linear Regression with PyTorch\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "source": [
    "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "```\n",
    "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "targets.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "type(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n        [ 91.,  88.,  64.],\n        [ 87., 134.,  58.],\n        [102.,  43.,  37.],\n        [ 69.,  96.,  70.]])\ntensor([[ 56.,  70.],\n        [ 81., 101.],\n        [119., 133.],\n        [ 22.,  37.],\n        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Convert inputs and targets to tensor\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.array([[73, 67, 42],\n",
    "               [91, 88, 64]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[73, 67, 42],\n",
       "       [91, 88, 64]])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[10,  2],\n",
       "       [ 5,  2],\n",
       "       [ 2,  2]])"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "m2 = np.array([[10, 5, 2],\n",
    "               [2, 2, 2]])\n",
    "\n",
    "\n",
    "m2 = m2.transpose()\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[73, 67, 42],\n",
       "        [91, 88, 64]]),\n",
       " array([[10,  2],\n",
       "        [ 5,  2],\n",
       "        [ 2,  2]]))"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "mult = m1 @ m2\n",
    "m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1149,  364],\n",
       "       [1478,  486]])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1149"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "10 * 73 + 5 * 67 + 42 * 2"
   ]
  },
  {
   "source": [
    "## Linear regression model from scratch\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0595, -0.7246, -1.1100],\n        [ 0.5987,  0.5227,  1.1704]], requires_grad=True)\ntensor([ 0.2645, -1.1283], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "source": [
    "Model is a function that performs a matrix multiplication of  the `inputs` and the weights `w` (transposed) and adds the bias `b`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "source": [
    "@ represents matrix multiplication in PyTorch, and the .t method returns the transpose of a tensor."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-100.3491,  127.9222],\n",
       "        [-139.9440,  174.2527],\n",
       "        [-166.3760,  188.8781],\n",
       "        [ -78.0241,  125.7189],\n",
       "        [-151.0923,  172.2844]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "source": [
    "## Loss function\n",
    "* Calculate the difference between the two matrices (`preds` and `targets`).\n",
    "* Square all elements of the difference matrix to remove negative values.\n",
    "* Calculate the average of the elements in the resulting matrix.\n",
    "\n",
    "The result is a single number, known as the **mean squared error** (MSE)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "source": [
    "`torch.sum` returns the sum of all the elements in a tensor. The `.numel` method of a tensor returns the number of elements in a tensor. Let's compute the mean squared error for the current predictions of our model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(25182.1992, grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "loss = mse(preds, targets)\n",
    "loss"
   ]
  },
  {
   "source": [
    "## Compute Gradients"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.0595, -0.7246, -1.1100],\n        [ 0.5987,  0.5227,  1.1704]], requires_grad=True)\ntensor([[-16816.3848, -19370.5469, -11780.5176],\n        [  5696.3320,   5348.9810,   3486.4526]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-16816.3848, -19370.5469, -11780.5176],\n",
       "        [  5696.3320,   5348.9810,   3486.4526]])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "w\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(25182.1992, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5# Let's verify that the loss is actually lower\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(25182.1992, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's verify that the loss is actually lower\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 0., 0.],\n        [0., 0., 0.]])\ntensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "source": [
    "## Train the model using gradient descent\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ -70.0272,  118.6802],\n        [-100.0535,  162.1299],\n        [-118.9544,  174.7318],\n        [ -48.1812,  116.3179],\n        [-112.6449,  160.7777]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(17259.8535, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-13683.1738, -15996.4248,  -9699.9590],\n        [  4744.0479,   4330.8818,   2857.0432]])\ntensor([-166.1722,   54.5275])\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.2455, -0.3709, -0.8952],\n        [ 0.4943,  0.4259,  1.1069]], requires_grad=True)\ntensor([ 0.2682, -1.1295], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(11917.6533, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "source": [
    "We have already achieved a significant reduction in the loss merely by adjusting the weights and biases slightly using gradient descent."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Train for multiple epochs\n",
    "\n",
    "To reduce the loss further, we can repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an _epoch_. Let's train the model for 100 epochs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(800):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(14.3364, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 57.7182,  70.1078],\n",
       "        [ 78.5452, 101.2477],\n",
       "        [126.1328, 131.9650],\n",
       "        [ 23.6265,  37.0230],\n",
       "        [ 94.1183, 119.9138]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[jovian] Attempting to save notebook..\n",
      "[jovian] Updating notebook \"aleksmn/practice-linear-regression\" on https://jovian.ai/\n",
      "[jovian] Uploading notebook..\n",
      "[jovian] Capturing environment..\n",
      "[jovian] Error: Failed to read Anaconda environment using command: \"conda env export -n base --no-builds\"\n",
      "[jovian] Committed successfully! https://jovian.ai/aleksmn/practice-linear-regression\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://jovian.ai/aleksmn/practice-linear-regression'"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "import jovian\n",
    "jovian.commit(filename=\"practice-linear-regression.ipynb\")"
   ]
  },
  {
   "source": [
    "## Linear regression using PyTorch built-ins\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.],\n",
       "        [ 74.,  66.,  43.],\n",
       "        [ 91.,  87.,  65.],\n",
       "        [ 88., 134.,  59.],\n",
       "        [101.,  44.,  37.],\n",
       "        [ 68.,  96.,  71.],\n",
       "        [ 73.,  66.,  44.],\n",
       "        [ 92.,  87.,  64.],\n",
       "        [ 87., 135.,  57.],\n",
       "        [103.,  43.,  36.],\n",
       "        [ 68.,  97.,  70.]])"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "source": [
    "## Dataset and DataLoader\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "# Define datasets\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[103.,  43.,  36.],\n        [ 87., 134.,  58.],\n        [ 68.,  97.,  70.],\n        [102.,  43.,  37.],\n        [ 91.,  87.,  65.]])\ntensor([[ 20.,  38.],\n        [119., 133.],\n        [102., 120.],\n        [ 22.,  37.],\n        [ 80., 102.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "source": [
    "## nn.Linear"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[-0.2334, -0.2486,  0.0896],\n        [-0.3911,  0.1839,  0.5082]], requires_grad=True)\nParameter containing:\ntensor([ 0.0592, -0.3712], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2334, -0.2486,  0.0896],\n",
       "         [-0.3911,  0.1839,  0.5082]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0592, -0.3712], requires_grad=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-29.7873,   5.2510],\n",
       "        [-37.3287,  12.7449],\n",
       "        [-48.3703,  19.7200],\n",
       "        [-31.1273, -13.5545],\n",
       "        [-33.6445,  25.8700],\n",
       "        [-29.7721,   4.6759],\n",
       "        [-36.9905,  13.0692],\n",
       "        [-48.5141,  19.8370],\n",
       "        [-31.1425, -12.9795],\n",
       "        [-33.3215,  26.7693],\n",
       "        [-29.4491,   5.5753],\n",
       "        [-37.3135,  12.1698],\n",
       "        [-48.7085,  19.3957],\n",
       "        [-31.4503, -14.4538],\n",
       "        [-33.6597,  26.4450]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "source": [
    "## Loss function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(10663.5127, grad_fn=<MseLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "loss = loss_fn(model(inputs), targets)\n",
    "loss"
   ]
  },
  {
   "source": [
    "## Optimizer\n",
    "\n",
    "Instead of manually manipulating the model's weights & biases using gradients, we can use the optimizer `optim.SGD`. SGD is short for \"stochastic gradient descent\". The term _stochastic_ indicates that samples are selected in random batches instead of as a single group."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "source": [
    "## Train the model\n",
    "\n",
    "We are now ready to train the model. We'll follow the same process to implement gradient descent:\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero\n",
    "\n",
    "The only change is that we'll work batches of data instead of processing the entire training data in every iteration. Let's define a utility function `fit` that trains the model for a given number of epochs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "\n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Train with batches of data\n",
    "        for xb, yb in train_dl:\n",
    "\n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "\n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "\n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "\n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [10/100], Loss: 196.8401\nEpoch [20/100], Loss: 161.1165\nEpoch [30/100], Loss: 95.8791\nEpoch [40/100], Loss: 56.4104\nEpoch [50/100], Loss: 69.7375\nEpoch [60/100], Loss: 34.4572\nEpoch [70/100], Loss: 6.0207\nEpoch [80/100], Loss: 6.2167\nEpoch [90/100], Loss: 16.8885\nEpoch [100/100], Loss: 6.5597\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 58.1426,  70.7555],\n",
       "        [ 81.9050, 100.3173],\n",
       "        [117.0020, 132.5575],\n",
       "        [ 27.2462,  40.2869],\n",
       "        [ 97.8682, 116.5772],\n",
       "        [ 57.0528,  69.7381],\n",
       "        [ 81.6517, 100.3470],\n",
       "        [117.2822, 133.1449],\n",
       "        [ 28.3360,  41.3042],\n",
       "        [ 98.7047, 117.6243],\n",
       "        [ 57.8893,  70.7852],\n",
       "        [ 80.8152,  99.3000],\n",
       "        [117.2553, 132.5278],\n",
       "        [ 26.4097,  39.2398],\n",
       "        [ 98.9580, 117.5946]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 57.,  69.],\n",
       "        [ 80., 102.],\n",
       "        [118., 132.],\n",
       "        [ 21.,  38.],\n",
       "        [104., 118.],\n",
       "        [ 57.,  69.],\n",
       "        [ 82., 100.],\n",
       "        [118., 134.],\n",
       "        [ 20.,  38.],\n",
       "        [102., 120.]])"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[54.8981, 67.9631]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "model(torch.tensor([[75, 63, 44.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}